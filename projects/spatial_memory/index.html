<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Spatial Memory | Nolan &amp; Sürmeli Labs </title> <meta name="author" content="Nolan &amp; Sürmeli"> <meta name="description" content="The Nolan &amp; Sürmeli Labs website. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%A0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mattnolanlab.github.io/projects/spatial_memory/"> </head> <body class=" sticky-bottom-footer"> <header> <div class="container"> <div class="carousel-container" style="position: relative; width: fit-content; padding: 0;"> <div id="carousel" class="carousel"> <img class="carousel-image" src="/assets/img/banners/banner1.jpg" alt="Banner Image"> <img class="carousel-image" src="/assets/img/banners/banner2.jpg" alt="Banner Image"> <img class="carousel-image" src="/assets/img/banners/banner3.jpg" alt="Banner Image"> <img class="carousel-image" src="/assets/img/banners/banner4.jpg" alt="Banner Image"> </div> </div> </div> <nav id="navbar" class="navbar container navbar-light navbar-expand-sm sticky-top" role="navigation"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/data-and-code/">Data &amp; Code </a> </li> <li class="nav-item "> <a class="nav-link" href="/nolan-lab/">Nolan Lab </a> </li> <li class="nav-item "> <a class="nav-link" href="/surmeli-lab/">Sürmeli Lab </a> </li> <li class="nav-item "> <a class="nav-link" href="/lab-values/">Lab Values </a> </li> </ul> </div> </nav> <style>.carousel-container{height:15vw;max-height:160px;overflow:hidden}.carousel{width:100%;height:400%;animation:carousel 100s infinite linear alternate}.carousel-image{float:left;width:100%;height:25%}@keyframes carousel{0%,20%{transform:translateY(0)}22%,40%{transform:translateY(-25%)}42%,60%{transform:translateY(-50%)}62%,80%{transform:translateY(-75%)}82%,85%{transform:translateY(-50%)}87%,90%{transform:translateY(-25%)}92%,100%{transform:translateY(0)}}</style> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Spatial Memory</h1> <p class="post-meta"> by Kaja Kubickova </p> <p class="post-description"></p> </header> <article> <h2 id="the-neural-map">The Neural Map</h2> <p>Our sense of navigation is not something we tend to consider too deeply in our day-to-day lives. Nevertheless, we somehow have a subconscious knowledge of were we are in the world and where we are going. We use it everywhere - to walk home, to go to the grocery store, to walk to the bathroom in the middle of the night.</p> <p>How we navigate is largely dependent on what information is available to us. The brain is complex and uses a variety of strategies to determine our position, relative to other landmarks and to start or goal locations. Among those is beaconing, a strategy where we use a distant object to navigate to - say, “Hey, there’s a neon sign here saying ‘Pub’” - that’s probably the entrance to the pub. But what if you don’t have those clues?</p> <hr> <h2 id="path-integration">Path Integration</h2> <p>Say you are out on a hike with your friends. You are full of energy during the day and make plenty of detours before you get to the campsite and settle in for a restful night, listening to the soothing patter of rain on the tent. Oh no! It is 2am and you have woken up in what an optimist would call a ‘puddle’, and anyone else might label ‘a decidedly sizable body of water’.</p> <p><em>So much for the guy on Facebook Marketplace promising that the tent was waterproof.</em></p> <p>You and your friend make the decision to trek back to the car park. You wish one of you had brought a headlamp at least - you can not use any landmarks to navigate. Despite that, you somehow manage to make it back in one piece, going straight from the campsite to the carpark without any of the diversions you had undertaken on the way there. <em>How?</em></p> <p>Two types of sensory information are required to update where we think we are: <em>Allothetic information</em> we get from the outside environment, like that ‘Pub’ sign. <em>Idiothetic information</em> is generated by the body itself. For example, the brain signals responsible for walking to the pub also provide us with information about how far we have walked so far. Path integration uses these idiothetic cues to transverse the mental map in our head. For example, a mouse that is foraging and takes a long, winding trajectory towards its goal will have ‘calculated’ its displacement from its nest and can make a beeline safely back if it suddenly runs into a fox.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/game/mouse_integration-480.webp 480w,/assets/img/game/mouse_integration-800.webp 800w,/assets/img/game/mouse_integration-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/game/mouse_integration.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="mouse integration" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Studying path integration is complicated by the fact that it’s only one part of the mechanism behind navigation. It’s an error-prone system, and so it works in combination with other information to create a path - for example, a mouse might use remembered landmarks, olfaction and even way-marking to navigate through an environment. Studying the neurons specifically involved in path integration therefore requires us to remove all other possibilities but using path integration. How do we do <em>that?</em></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/game/pi_exp_1-480.webp 480w,/assets/img/game/pi_exp_1-800.webp 800w,/assets/img/game/pi_exp_1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/game/pi_exp_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="pi 1" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>One way of studying path integration is using virtual reality. Mice run through a VR corridor on a treadmill until there is a visual cue. If they stop at the visual cue, they get a treat. After a few repetitions, the visual cue is removed - yet the mice still stop in the place where the visual cue <em>would have been</em>. If there are no external cues for the mice to see, how do they know when to stop?</p> <p>The mice can not use other navigational strategies, such as beaconing, because there are no allothetic cues, so they are left with path integration <a class="citation" href="#WOS:000878031400006">(Tennant et al., 2022)</a>. They might have remembered the time it took to run to the reward zone - but when the speed of the treadmill was changed, the mice did not overshoot the reward zone, despite running faster. This implies they were not measuring the time, but were instead getting their information from a collection of self-motion cues. This includes proprioception (the sense of your self-position and self-movement) along with the vestibular system (your inner ear, which provides a sense of balance and awareness of our head and body in space) and motor efference. Over longer distances, the accuracy of this system drops without external input such as landmarks, as small errors start to accumulate and the mice start to stop further away from the reward zone.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/game/pi_exp_2-480.webp 480w,/assets/img/game/pi_exp_2-800.webp 800w,/assets/img/game/pi_exp_2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/game/pi_exp_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="pi 1" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="cell-types">Cell types</h2> <p>Path integration is just one of the many navigational strategies we want to study to understand the basis of the neural map. There are many specialised cell types involved in navigation. For the purpose of this website, let us focus on three: place cells, grid cells, and head direction cells.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/game/cell_types-480.webp 480w,/assets/img/game/cell_types-800.webp 800w,/assets/img/game/cell_types-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/game/cell_types.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="cell types" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Grid cells</strong> are place-modulated neurons located primarily in the entorhinal cortex that fire periodically in space, mapping a triangular grid across an environment. As an animal moves through space, grid cells fire to create hexagonal patterns that allow us to map this space. Again, a population of grid cells alone can encode a spatial map <a class="citation" href="#10.7554/eLife.89356">(Clark &amp; Nolan, 2024)</a>.</p> <p><strong>Place cells</strong> located in the hippocampus, fire when an animal enters a specific location in space. A population of place cells alone can encode a spatial map.</p> <p><strong>Head direction cells</strong> are primarily found in the postsubiculum, and provide directional information by preferentially firing in specific directions. A population of head direction cells can encode which direction you are facing in your spatial map <a class="citation" href="#WOS:000568891400011">(Gerlei et al., 2020)</a>.</p> <p>These cells potentially have uses outside of encoding physical space - their coding mechanism may be used for more general problem sets, such as cognitive mapping. Cognitive mapping refers to swapping out the three-dimensional world we interact with for a different, continuous dimension that represents an abstract concept. The same way we might encode the map of our room, we might use the hexagonal-firing properties of grid cells to represent, for example, conceptual spaces, such as hierarchically organizing ideas within our brain, or recording temporal sequences of events.</p> <script src="https://cdn.jsdelivr.net/npm/phaser@3.60.0/dist/phaser-arcade-physics.min.js"></script> <script type="module" src="/kaja_game/js/main.js"></script> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#d63230"><a href="/nolan-lab">NOLAN</a></abbr> </div> <div id="10.7554/eLife.89356" class="col-sm-8"> <div class="title">Task-anchored grid cell firing is selectively associated with successful path integration-dependent behaviour</div> <div class="author"> Harry Clark ,  and  Matthew F. Nolan </div> <div class="periodical"> <em>eLife</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/MattNolanLab/eLife_Grid_anchoring_2024" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://datashare.ed.ac.uk/handle/10283/8723" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> <a href="https://doi.org/10.7554/eLife.89356" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Grid firing fields have been proposed as a neural substrate for spatial localisation in general or for path integration in particular. To distinguish these possibilities, we investigate firing of grid and non-grid cells in the mouse medial entorhinal cortex during a location memory task. We find that grid firing can either be anchored to the task environment, or can encode distance travelled independently of the task reference frame. Anchoring varied between and within sessions, while spatial firing of non-grid cells was either coherent with the grid population, or was stably anchored to the task environment. We took advantage of the variability in task-anchoring to evaluate whether and when encoding of location by grid cells might contribute to behaviour. We find that when reward location is indicated by a visual cue, performance is similar regardless of whether grid cells are task-anchored or not, arguing against a role for grid representations when location cues are available. By contrast, in the absence of the visual cue, performance was enhanced when grid cells were anchored to the task environment. Our results suggest that anchoring of grid cells to task reference frames selectively enhances performance when path integration is required.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#d63230"><a href="/nolan-lab">NOLAN</a></abbr> </div> <div id="WOS:000878031400006" class="col-sm-8"> <div class="title">Spatial representation by ramping activity of neurons in the retrohippocampal cortex</div> <div class="author"> Sarah A. Tennant ,  Harry Clark ,  Ian Hawes , and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Wing Kin Tam, Junji Hua, Wannan Yang, Klara Z. Gerlei, Emma R. Wood, Matthew F. Nolan' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">6 more authors</span> </div> <div class="periodical"> <em>Current Biology</em>, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/MattNolanLab/Ramp_analysis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://datashare.ed.ac.uk/handle/10283/777" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> <a href="https://doi.org/10.1016/j.cub.2022.08.050" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Neurons in the retrohippocampal cortices play crucial roles in spatial memory. Many retrohippocampal neu-rons have firing fields that are selectively active at specific locations, with memory for rewarded locations associated with reorganization of these firing fields. Whether this is the sole strategy for representing spatial memories is unclear. Here, we demonstrate that during a spatial memory task retrohippocampal neurons encode location through ramping activity that extends across segments of a linear track approaching and following a reward, with the rewarded location represented by offsets or switches in the slope of the ramping activity. Ramping representations could be maintained independently of trial outcome and cues marking the reward location, indicating that they result from recall of the track structure. When recorded in an open arena, neurons that generated ramping activity during the spatial memory task were more numerous than grid or border cells, with a majority showing spatial firing that did not meet criteria for classification as grid or border representations. Encoding of rewarded locations through offsets and switches in the slope of ramping activ-ity also emerged in recurrent neural network models trained to solve a similar spatial memory task. Impaired performance of model networks following disruption of outputs from ramping neurons is consistent with this coding strategy supporting navigation to recalled locations of behavioral significance. Our results suggest that encoding of learned spaces by retrohippocampal networks employs both discrete firing fields and continuous ramping representations. We hypothesize that retrohippocampal ramping activity mediates readout of learned models for goal-directed navigation.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#d63230"><a href="/nolan-lab">NOLAN</a></abbr> </div> <div id="WOS:000568891400011" class="col-sm-8"> <div class="title">Grid cells are modulated by local head direction</div> <div class="author"> Klara Gerlei ,  Jessica Passlack ,  Ian Hawes , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Brianna Vandrey, Holly Stevens, Ioannis Papastathopoulos, Matthew F. Nolan' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">4 more authors</span> </div> <div class="periodical"> <em>Nature Communications</em>, Aug 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/MattNolanLab/grid_cell_analysis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://datashare.is.ed.ac.uk/handle/10283/777" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> <a href="https://doi.org/10.1038/s41467-020-17500-1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Grid and head direction codes represent cognitive spaces for navigation and memory. Pure grid cells generate grid codes that have been assumed to be independent of head direction, whereas conjunctive cells generate grid representations that are tuned to a single head direction. Here, we demonstrate that pure grid cells also encode head direction, but through distinct mechanisms. We show that individual firing fields of pure grid cells are tuned to multiple head directions, with the preferred sets of directions differing between fields. This local directional modulation is not predicted by previous continuous attractor or oscillatory interference models of grid firing but is accounted for by models in which pure grid cells integrate inputs from co-aligned conjunctive cells with firing rates that differ between their fields. We suggest that local directional signals from grid cells may contribute to downstream computations by decorrelating different points of view from the same location. Neurons with grid firing fields are thought to play important roles in spatial cognition. Here, the authors show that in contrast to assumptions underlying current models and analyses, grid fields are modulated by local head direction; this suggests different mechanisms and new roles for grid firing.</p> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> <div class="footer-element copyright"> © Copyright 2024 Nolan &amp; Sürmeli. </div> <div class="footer-element"> <a href="https://www.ed.ac.uk/" rel="external nofollow noopener" target="_blank"> <img class="logo" src="/assets/img/uoe.png" alt="University of Edinburgh logo" style="width: 100%;"> </a> </div> <div class="footer-element"> <a href="https://discovery-brain-sciences.ed.ac.uk/" rel="external nofollow noopener" target="_blank"> <img class="logo" src="/assets/img/cdbs.png" alt="Centre for Discovery Brain Sciences logo" style="width: 100%;"> </a> </div> <div class="footer-element"> <a href="https://sidb.org.uk/" rel="external nofollow noopener" target="_blank"> <img class="logo" src="/assets/img/SIDB.gif" alt="Simons Initiative for the Developing Brain logo" style="width: 100%;"> </a> </div> </div> <style>.container{display:flex;justify-content:space-between;align-items:center}.footer-element{flex:1;margin:0 20px}.copyright{flex:2}@media(max-width:768px){.container{flex-direction:column}.footer-element{margin:20px 0}.copyright{flex:1}.logo{max-width:50%}}</style> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>